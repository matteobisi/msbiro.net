[{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["first"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["first"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/cyberark-conjur-131-released/","tags":["first"],"title":"My 1st post"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/posts/cyberark-conjur-131-released/","tags":["cyberark","conjur","13.1"],"title":"CyberArk Conjur 13.1 Released"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"A couple of weeks ago, CyberArk released a new and interesting version of Conjur: 13.1.\nThis point release is really interesting because it brings important under-the-hood updates that aim to increase the resiliency of followers.\nIf you want to read more about this release, please check out the article I wrote on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-131-released/","tags":["cyberark","conjur","13.1"],"title":"CyberArk Conjur 13.1 Released"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"},{"content":"Privacy Notice\nLast updated: June 04, 2025\nWho We Are This website www.msbiro.net is a personal blog operated by Matteo Bisi.\nFor any privacy-related inquiries, you can contact me at mbisi@msbiro.net.\nWhat Information We Collect This website itself does not collect personal data from visitors.\nHowever, when you visit this site, certain technical information (such as your IP address, browser type, and device information)\nis automatically collected and processed by our hosting provider, Cloudflare, to deliver the website securely and efficiently.\nUse of Cookies This site does not use cookies for tracking or analytics purposes.\nAnalytics No analytics or tracking tools are enabled on this site.\nHow Your Information Is Used Cloudflare may process your IP address and basic connection details for the following purposes:\nDelivering website content Ensuring network and information security Detecting and mitigating malicious activity This processing is based on Cloudflare’s legitimate interest in providing a secure and reliable service.\nData Sharing Your technical information may be processed by Cloudflare in accordance with their Privacy Policy.\nNo personal data is shared by me with any third parties.\nYour Rights As an EU resident, you have the right to access, rectify, or erase your personal data, and to restrict or object to its processing.\nFor requests regarding data processed by Cloudflare, please refer to their privacy policy linked above.\nChanges to This Policy This privacy notice may be updated from time to time. Please check back periodically for updates.\nDisclaimer This is my personal blog. All statements and content published here reflect my own opinions and do not represent the views of my employer, ReeVo S.p.A.,\nor any other organization with which I am affiliated.\nIn case of any overlap with my professional activity, please note that this blog is independent and not an official communication channel of my employer.\n","permalink":"http://localhost:1313/privacy-policy/","tags":["privacy-policy"],"title":"Privacy Policy"},{"content":"Hello, I’m Matteo Bisi.\nI’m a DevSecOps Team Leader currently living in Galway, Ireland, but originally from Italy.\nWith a passion for both technology and teamwork, I lead my team in building and securing cloud-native infrastructures using both open source and enterprise tools.\nMy journey has taken me across different roles, giving me a unique perspective on how diverse teams collaborate and innovate.\nI’m particularly interested in automating security practices, managing secrets at scale, and empowering development teams to deliver secure software efficiently.\nOutside of work, I enjoy exploring the beautiful Irish countryside, planning my next family trip, and cooking some Italian recipes.\nThrough this blog, I hope to share insights, best practices, and lessons learned from my experiences leading DevSecOps teams.\nYou can find more information about my CV on my LinkedIn profile.\nMy preavious blogs about Collaboration solutions are available here:\nitalian blog english blog ","permalink":"http://localhost:1313/aboutme/","tags":["biography"],"title":"About Me - Matteo Bisi"},{"content":"A couple of weeks ago, CyberArk released a new and interesting version of Conjur: 13.1.\nThis point release is really interesting because it brings important under-the-hood updates that aim to increase the resiliency of followers.\nIf you want to read more about this release, please check out the article I wrote on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-131-released/","tags":["cyberark","conjur","13.1"],"title":"CyberArk Conjur 13.1 Released"},{"content":"Yesterday, KubeCon NA in Chicago came to a close, so now we can start looking forward to KubeCon EU 2024,\nwhich will take place in Paris from March 19th to 22nd, 2024 😊.\nFor Paris, early bird registrations are open until November 28th, and it’s still possible to submit proposals for the call for papers.\nI wanted to share an interesting initiative called Kubetrain, which aims to help attendees reach Paris in a more environmentally sustainable way by choosing trains over planes.\nTo make the journey economically sustainable as well, the organizers of Kubetrain have arranged for sponsored carriages from several major European cities.\nThis innovative approach not only reduces carbon footprints but also provides opportunities for networking events during the trip!\nThe cities involved are as follows:\nAmsterdam Berlin London Lyon Milan Zurich The trip from Zurich is already “operational,” while arrangements for the other cities are still in progress.\nI encourage you to follow their website for updates and to potentially book your departure from your preferred city.\nI find this initiative incredibly interesting, kudos to the organizers!!\n","permalink":"http://localhost:1313/posts/kubecon-eu-2024-paris-kubetrain/","tags":["kubecon","kubetrain"],"title":"KubeCon EU 2024 Paris – Exploring the Kubetrain Initiative"},{"content":"I’ll start with a premise for those who may not already be familiar: the open-source software ecosystem often revolves around foundations, with the most famous probably being the Linux Foundation.\nIn the cloud-native domain, the reference foundation is the Cloud Native Computing Foundation, commonly known as CNCF.\nCNCF is a foundation created by the Linux Foundation in 2015, specifically to manage projects in the cloud-native domain. In simple terms, it can be defined as a third-party, vendor-neutral entity that oversees the development and activities related to major projects involving containerized technologies like Kubernetes.\nThe foundation consists of a large number of sub-entities and working groups that oversee various projects, and much of the work is done by volunteers. To participate, everyone must adhere to the CNCF’s code of conduct.\nWhen considering Kubernetes and the main projects associated with it, you can imagine the amount of work required to keep this system running and how many people—at all levels—are needed to contribute, both technically and non-technically.\nThroughout my career, I have always tried to be involved in the community surrounding my professional world—participating in events, speaking at them, and even organizing some myself.\nEven in my current role at SIGHUP, I have maintained the same approach. For the past few months, I have been part of the Italian team responsible for the Italian localization of the CNCF’s glossary.\nI share this with you because I find it extremely rewarding to participate in these kinds of initiatives. It’s a great way to meet new people, step a bit outside your comfort zone, and assist others—including people and companies you may not know—all for the sake of fostering a better ecosystem.\nAs you can imagine, contributions can be made at all levels, with different teams dedicated to different scopes. Of course, it’s common to work with people from all around the world and from diverse backgrounds.\nAs a colleague told me recently, “If you enter a meeting and feel like a fool compared to the other participants, it probably means you’re in the right place.” Participating in meetings—even as an observer—with high-level individuals is a great opportunity for professional growth.\nNow that I’ve piqued your interest, how can you participate or find a project that suits you?\nI suggest exploring the following links for information about CNCF events and projects:\nExplore all CNCF sites End User Community CNCF Slack CNCF repositories on GitHub What I’ve mentioned above also applies to another very interesting foundation, born in 2020, called the Open Source Security Foundation, commonly abbreviated as OpenSSF. This foundation is an initiative of the Linux Foundation and focuses on enhancing the security of open-source software.\nSince I work in security, I closely follow various initiatives of this foundation.\nAt the moment, due to time constraints, I’m not an active contributor, but members of my team have already had the opportunity to contribute and participate in various working group meetings. It’s important to always adhere to the code of conduct when participating and contributing.\nIn this case as well, I’ll provide you with some useful links where you can find collaboration ideas for OpenSSF:\nOpenSSF Working Groups Get Involved OpenSSF repositories on GitHub OpenSSF Slack ","permalink":"http://localhost:1313/posts/the-value-of-community-contributions-exploring-cncf-openssf/","tags":["community","cncf","openssf","contribution"],"title":"The Value of Community Contributions: Exploring CNCF and OpenSSF"},{"content":"During the previous days, CyberArk has released version 13.0 of Conjur Enterprise.\nWhat’s new? Who should consider upgrading, and why?\nI’ve published an article on these topics here on the SIGHUP blog.\n","permalink":"http://localhost:1313/posts/conjur-13-is-available/","tags":["conjur","cyberark","13.0"],"title":"CyberArk Conjur 13 has been released."},{"content":"CyberArk Conjur is released as an appliance and distributed as container images to enable fast, error-free setup.\nThe supported container runtimes include:\nDocker 20.10 or later Mirantis Container Runtime 20.10 Podman 3.x, 4.x While working with multiple Conjur environments in our labs and at customer sites, we noticed that log rotation (for Conjur, Nginx, cluster, etc.) did not function correctly on Podman, although it worked as expected on Docker.\nAfter some investigation with the excellent CyberArk support team, we identified the solution:\nThe Conjur container needs to be re-created with the AUDIT_WRITE capability added:\npodman run \\ ... --cap-add AUDIT_WRITE \\ ... registry.tld/conjur-appliance:12.9.0 To minimize noise in the Nginx logs, it is also necessary to set the following permission inside every Conjur container:\nchmod 701 /opt/cyberark/dap/log/nginx The CyberArk support team was, as always, extremely helpful in assisting us and collaborating to find this solution. These issues are now documented in the CyberArk documentation and should be addressed in future updates.\nIf you experience the same issue, I recommend contacting CyberArk support to confirm whether this solution is applicable to your environment.\n","permalink":"http://localhost:1313/posts/resolving-podman-log-rotation-issue-conjur-enterprise-129/","tags":["conjur","cyberark","podman","12.9"],"title":"Resolving Podman Log Rotation Issues in CyberArk Conjur Container 12.9 Deployments"},{"content":"I believe it’s important to start with a premise:\nIn this article, I’ll talk about a product/service built and offered by my current employer, SIGHUP.\nNo one from my company has asked me to publish this blog post here; these are my honest opinions about Secure Containers.\nSecure Containers is a paid service built by SIGHUP that provides secure, hardened, and updated container base images.\nDevelopers working with containers and images now enjoy several advantages compared to the past, such as standardization, automation, and faster release times.\nOne of the most underestimated aspects of working with containers is the need to start from base images that must be chosen carefully to avoid issues such as:\nBugs CVEs Outdated images Malicious code It’s clear that having constantly updated base images with the fewest possible CVEs is crucial.\nAny problems in the base image will be replicated in your container, which could then be running in production environments.\nKeeping base images updated and secure is a significant responsibility, often requiring dedicated attention from someone in the company—taking them away from other tasks.\nThis is where the Secure Containers service can help, offering the following advantages:\nComprehensive container catalog Proactively patched against all known CVEs and vulnerabilities Prometheus-friendly images Notifications, support status, and planned obsolescence Support and clear SLAs If you’re interested in Secure Containers, please visit the dedicated site to find more information and FAQs.\nYou’ll also have the opportunity to enable a free trial of the service.\nIf you’d like to read more about the security of container base images,\ncheck out this article where I’ll explore the topic in greater depth.\n","permalink":"http://localhost:1313/posts/sighup-secure-container-how-choose-base-image-security/","tags":["ssc","secure containers","security","supply-chain"],"title":"SIGHUP Secure Containers: how do you choose the oci base image for your workload?"},{"content":"Being able to work safely in cybersecurity requires knowledge, attention to detail, and a solid portfolio of reliable software.\nOne of the tools I have learned about and used in recent months is Snyk.\nCalling Snyk a “tool” isn’t quite accurate—it’s a security platform that offers a suite of tools capable of operating on any codebase, including:\nCode (SAST) Open Source (SCA) Containers Infrastructure as Code Cloud In recent years, the amount of code produced has grown exponentially. The availability of countless open-source libraries and containers has accelerated development, but how can we be sure that all these resources are secure?\nHow can developers be responsible for the security of their own code as well as the work of others? How can security officers manage this scenario without becoming a bottleneck to productivity?\nSnyk helps by integrating its tools into IDEs, Git repositories, and CI/CD pipelines, providing fast analysis and suggesting solutions for detected issues.\nFor example, Snyk can be installed as a VSCode plugin or set up to scan Git repositories. If an issue is found, it can automatically open a pull request proposing a fix.\nSnyk is also fully integrable into customer environments, supporting both access and security policies to ensure full compliance with customer needs. Customizable dashboards and reports are available, enabling security officers to quickly understand the security status of a project.\nAnother interesting feature is that Snyk has built an open-source vulnerability database that catalogs vulnerabilities and provides examples and tutorials for developers.\nThe best part is that testing Snyk is easy—a free (limited) plan is available!\nIf you’re interested in learning more about Snyk, please read the blog article published by my colleague Luca Bandini about our experience with Snyk,\nwhich we also used to check the code of Fury, the Kubernetes distribution developed by SIGHUP.\n","permalink":"http://localhost:1313/posts/how-make-developers-and-security-officers-happy-with-snyk/","tags":["snyk","sast","sca","supply-chain"],"title":"How Is It Possible to Make Both Developers and Security Officers Happy? Try Snyk!"},{"content":"During our work with a CyberArk Conjur environment, we encountered strange behavior during the Conjur follower setup.\nThe setup process on the follower would start, the seed was received, imported, and expanded, but after a few more steps, the process would hang and end with a generic “System Error.”\nAfter displaying the error message, the Conjur follower would restart.\nWe performed troubleshooting inside the Conjur Follower pod and verified that the follower could connect to the Conjur API leader successfully, but it was unable to connect to the Postgres database and complete the initial replication.\nThe correct way to verify Postgres connectivity from the follower to the leader is with the following command:\necho \"\" | openssl s_client -starttls postgres -connect \u003clb_DNS\u003e:5432 -showcerts If the server certificate is returned, Postgres connectivity is working as expected.\nIn our case, we were unable to retrieve the certificate, which pointed us to an issue with the network load balancer. A colleague was able to fix the problem there.\nThanks to CyberArk support for providing us with the openssl command, which is easy to run from the container or any server. We had tried other verification methods, but openssl s_client is readily available on most containers and servers.\nFor more information about openssl s_client and its options, check out this helpful blog post.\n","permalink":"http://localhost:1313/posts/troubleshooting-conjur-follower-setup-postgres-connectivity/","tags":["conjur","follower","postgres","troubleshooting"],"title":"Troubleshooting CyberArk Conjur Follower Setup and Postgres Connectivity"},{"content":"As you may know, one of the key components of the CyberArk Conjur architecture is the Synchronizer, which is required to receive secrets from the Vault.\nLast week, I took charge of an abandoned Synchronizer version 11.7 that had not been working for some time and also needed to be upgraded to the latest 12.7 release.\nAfter completing the upgrade (check this link for the steps), the Windows service failed to start, and the log contained the following error:\n[5] [main] FATAL VaultConjurSynchronizer.Service.SynchronizerService - VCSS006F Failed to start CyberArk Vault-Conjur Synchronizer Service: CASVM035E Vault name is missing. After searching online, we found references to the CASOS log error for the Vault, where the documentation suggests contacting CyberArk support.\nFortunately, in the case of the Synchronizer, we were able to resolve the issue easily by editing the following file:\nC:\\Program Files\\CyberArk\\Synchronizer\\VaultConjurSynchronizer.exe.config The value of the key INTEGRATION_VAULT_NAME was blank. After filling it in with the correct vault name (as specified in vault.ini), the service started successfully and secrets synchronization resumed as expected.\n","permalink":"http://localhost:1313/posts/cyberark-vault-synchronizer-casvm035e-fix/","tags":["cyberark","synchronizer","CASVM035E"],"title":"CyberArk Vault Synchronizer – CASVM035E Vault Name Is Missing: How to Fix It"},{"content":"As you probably know, CyberArk hosts a major annual event called Impact, which this year took place in Boston.\nIn recent weeks, CyberArk has announced an exciting initiative: the CyberArk Impact World Tour, which will be hosted in several cities around the globe.\nIf you’re interested, you can find all the details on this page, including:\nCities involved Agenda Registration form Personally, I’ll be attending the event in Milan, scheduled for October 11th, 2022.\nI’m excited for the opportunity to attend some fascinating sessions and meet interesting people in person. See you there!\n","permalink":"http://localhost:1313/posts/cyberark-impact-world-tour-2022/","tags":["cyberark","impact","conference"],"title":"CyberArk Impact 2022 World Tour – Will You Be There?"},{"content":"During the past few weeks, I have described what a secrets manager is and provided an overview of the architecture and system requirements of CyberArk Conjur.\nA secrets manager can’t do its job if it can’t communicate with those who need to request secrets, and that’s where Conjur’s magic comes in!\nThe “authenticators” are responsible for the authentication process in Conjur and are specialized to do this in the most secure way, depending on the service.\nHere is the list of authenticators currently supported:\nAuthenticator Description authn Defines the Conjur default authenticator. Authentication for both users and hosts is based on an ID and API key. authn-oidc Leverages the identity layer provided by OIDC to allow applications to authenticate with Conjur and retrieve secrets needed for connecting to services such as a database. authn-iam Enables an AWS resource to use its AWS IAM role to authenticate with Conjur. authn-azure Enables an Azure resource to authenticate with Conjur authn-jwt Enables an application to authenticate to Conjur using a JWT from a JWT Provider. authn-gcp Enables a Google Cloud Platform resource to authenticate with Conjur authn-k8s Authenticates hosts that are Kubernetes resources, such as a Kubernetes namespace, deployment, stateful set, and others. Authentication is certificate-based using a mutual TLS connection. authn-ldap Authenticates users based on an LDAP directory. By default, after the initial setup, authn is the only authenticator enabled, and it is responsible for Conjur access using a username or API key (randomly generated between 51 and 56 characters).\nWhen integrations are needed, for example with a Kubernetes cluster, you need to activate and configure the authn-k8s authenticator. This authenticator can establish a secure mTLS connection compliant with the SPIFFE framework, as described in the following diagram (click here for more details).\nIf you need integrations with cloud identities that support JWT authentication, such as Google Apigee, you will enable the authn-jwt authenticator, which will perform the integrations as shown below:\nThese were just two examples among the many possible secure integrations enabled by the authenticators. The following is a more complete list:\nKubernetes (local or cloud) API gateway Jenkins Ansible Puppet Terraform Cloud services If the scenario described sounds interesting for your needs, Conjur could definitely be the right choice. Contact your sales representative at CyberArk or your preferred CyberArk business partner.\n","permalink":"http://localhost:1313/posts/cyberark-conjur-authenticators-integrations/","tags":["conjur","authenticators","spiffe","integrations"],"title":"CyberArk Conjur, authenticators and integrations"},{"content":"As I wrote in my last post, CyberArk Conjur is an enterprise secrets manager. , CyberArk Conjur is an enterprise secrets manager.\nIn this post, I’ll provide an architecture overview along with the main system requirements.\nConjur is currently available in two versions: Enterprise and open source (known as OSS).\nA “cloud” version will be available soon, offered as a SaaS solution.\nThis post focuses on the Enterprise version, which is similar but not identical to the OSS version.\nArchitecture Conjur is distributed as a Docker image, making deployment and configuration fast and secure.\nThe main services included in the appliance image are:\nnginx: Provides access to the administrative GUI and the API set for interacting with secrets. PostgreSQL database: Two databases, one for configurations and secrets, and one for audit logs. Conjur appliance: The core product. syslog-ng: Used to collect audit and access logs. The smallest common configuration for Conjur Enterprise is a three-node cluster with auto-failover, as shown in the following diagram:\nThe cluster architecture follows an active-passive model, with high availability guaranteed by a load balancer placed in front of the cluster. This load balancer switches the node accessed by applications in case of a failure.\nWithin the cluster, one node acts as the “leader node,” handling all read/write operations and providing the API for applications to interact with secrets.\nThe secondary nodes are called “standbys” and can be either synchronous or asynchronous, depending on the PostgreSQL replication setup.\nThese nodes are inactive and do not provide API services.\nIf the leader node fails, after a configurable period, the standbys will elect a new leader using etcd and the Raft consensus algorithm.\nIf auto-failover is not configured, manual promotion is required.\nIt is also possible to configure a primary site with auto-failover and a secondary site with asynchronous standbys (without auto-failover), ready to be promoted manually.\nThe final component of the architecture is the “follower,” a read-only replica of the leader. Followers allow secrets to be read at scale and are horizontally scalable components typically configured behind a load balancer to handle all types of read requests, including authentication, permission checks, and secret fetches.\nFollowers are usually installed on a Kubernetes cluster to serve applications with low latency.\nThe architecture diagram with followers could be expanded as shown below:\nSystem Requirements Production environment:\n4 cores 8 GB RAM 50 GB hard drive Test environment:\n2 cores 4 GB RAM 20 GB hard drive Supported container runtimes:\nDocker 1.13 or later Mirantis Container Runtime (MRC) 19.x, 20.10 on RHEL 8.x Kubernetes and OpenShift (only for the follower) Podman 3.3 and 3.4 The host server should run an operating system supported by the container runtime (the most popular are RHEL Server, RHEL-based, or Ubuntu Server LTS). To read more detail or updated versions please refer to this page.\nIf the customer environment also includes a CyberArk Vault server that needs to be synchronized with Conjur, the following are the requirements for a CyberArk Vault Synchronizer server:\n4 cores 8 GB RAM Windows Server 2012 R2 or later ","permalink":"http://localhost:1313/posts/cyberark-conjur-architecture-system-requirements/","tags":["conjur","cyberark","secrets manager"],"title":"CyberArk Conjur: A Quick Overview of Architecture and System Requirements"},{"content":"Security is always a complex topic to address, as an error or omission in processes can lead to serious economic or reputational damage for a company.\nWhen we talk about “secrets,” consider the following examples:\nUsernames Database passwords SSL certificates and keys SSH keys Cloud credentials Simply reading through this list helps to explain why this topic needs to be considered and handled carefully.\nSome common bad practices or risks include:\nHardcoding secrets in code Data breaches Password leaks Secrets pushed to public repositories With practices like lateral movement, just one compromised secret can be enough to compromise an entire environment. To help prevent these risks, there are tools known as “enterprise secrets managers.” I’d like to start a series of posts on this blog about CyberArk Conjur.\nConjur allows you to avoid direct use of secrets by leveraging a set of REST APIs, making it a programmable tool that can be accessed via URL or open source utilities.\nSecurity is enforced through security policies without slowing down the developers involved.\nCorporate security can be further improved with the use of rotators, which programmatically change secret values.\nIf other CyberArk software like PAS Vault is already in use, Conjur can be integrated using the Synchroniser component,\nproviding the same level of security for cloud-native infrastructure.\nConjur is available in two versions: enterprise and open source, each with distinct features.\nIn upcoming posts, I will explain details about the architecture, secrets management, and product news related to CyberArk Conjur.\n","permalink":"http://localhost:1313/posts/why-you-need-kubernetes-secrets-manager/","tags":["conjur","introduction","secrets manager"],"title":"CyberArk Conjur - why you (probably) need an enterprise secrets manager"},{"content":"Hello there! How are you?\nI’m really good! As you may have seen on my social media, starting from the 16th of May, I’ve begun a new position as Senior DevSecOps at SIGHUP.\nI’m really excited about this new opportunity, and I’m writing this post because it will also have an effect on this blog’s focus.\nThe topics will shift from previous subjects to cloud-native infrastructure security, starting with tools like CyberArk Conjur. The previous content on this blog will remain here forever. I believe it could be helpful for some time, and I also want to honor my HCL Ambassador role.\nI’d also love to add that my current role as organizer of the LetsConnect user group will remain unchanged.\nI hope to see you all again at our next event!\n","permalink":"http://localhost:1313/posts/new-job-devsecops-teamleader/","tags":["cloudnative","newjob","devsecops","security"],"title":"I've started a new journey as DevSecOps Team Leader"},{"content":"","permalink":"http://localhost:1313/search/","tags":null,"title":"Search"}]